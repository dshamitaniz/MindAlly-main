#!/bin/bash

# MindAlly Ollama Docker Setup Script
# This script sets up Ollama with Docker for the MindAlly project

echo "üöÄ Setting up Ollama with Docker for MindAlly..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    echo "Visit: https://docs.docker.com/get-docker/"
    exit 1
fi

# Check if Docker is running
if ! docker info &> /dev/null; then
    echo "‚ùå Docker is not running. Please start Docker first."
    exit 1
fi

echo "‚úÖ Docker is installed and running"

# Stop and remove existing Ollama container if it exists
echo "üßπ Cleaning up existing Ollama container..."
docker stop ollama 2>/dev/null || true
docker rm ollama 2>/dev/null || true

# Pull and run Ollama container
echo "üì¶ Pulling and starting Ollama container..."
docker run -d \
  --name ollama \
  -p 11434:11434 \
  -v ollama:/root/.ollama \
  --restart unless-stopped \
  ollama/ollama

# Wait for container to start
echo "‚è≥ Waiting for Ollama to start..."
sleep 10

# Check if container is running
if ! docker ps | grep -q ollama; then
    echo "‚ùå Failed to start Ollama container"
    exit 1
fi

echo "‚úÖ Ollama container is running"

# Pull recommended models
echo "üì• Pulling recommended AI models..."

models=("llama3:latest" "mistral:latest" "phi3:latest")

for model in "${models[@]}"; do
    echo "üì• Pulling $model..."
    docker exec ollama ollama pull "$model"
    if [ $? -eq 0 ]; then
        echo "‚úÖ Successfully pulled $model"
    else
        echo "‚ö†Ô∏è  Failed to pull $model (continuing...)"
    fi
done

# Test connection
echo "üîç Testing Ollama connection..."
sleep 5

if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "‚úÖ Ollama is accessible at http://localhost:11434"
else
    echo "‚ö†Ô∏è  Ollama might not be fully ready yet. Try again in a few minutes."
fi

# Display status
echo ""
echo "üéâ Ollama setup complete!"
echo ""
echo "üìã Setup Summary:"
echo "   ‚Ä¢ Container: ollama"
echo "   ‚Ä¢ Port: 11434"
echo "   ‚Ä¢ URL: http://localhost:11434"
echo "   ‚Ä¢ Models: llama3:latest, mistral:latest, phi3:latest"
echo ""
echo "üîß Useful Commands:"
echo "   ‚Ä¢ Check status: docker ps | grep ollama"
echo "   ‚Ä¢ View logs: docker logs ollama"
echo "   ‚Ä¢ Stop: docker stop ollama"
echo "   ‚Ä¢ Start: docker start ollama"
echo "   ‚Ä¢ Pull model: docker exec ollama ollama pull <model-name>"
echo "   ‚Ä¢ List models: docker exec ollama ollama list"
echo ""
echo "üåê For Docker Desktop users:"
echo "   ‚Ä¢ Use: http://host.docker.internal:11434"
echo ""
echo "üêß For WSL2 users:"
echo "   ‚Ä¢ Use: http://172.17.0.1:11434"
echo ""
echo "‚ú® Your MindAlly app should now be able to connect to Ollama!"